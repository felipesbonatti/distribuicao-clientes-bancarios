# ğŸ¦ Sistema de DistribuiÃ§Ã£o Inteligente de Carteira de Clientes

<div align="center">

![License](https://img.shields.io/badge/license-MIT-00D4FF?style=for-the-badge&logo=mit&logoColor=white)
![Python](https://img.shields.io/badge/Python-3.8+-3776AB?style=for-the-badge&logo=python&logoColor=white)
![PySpark](https://img.shields.io/badge/PySpark-3.4+-E25A1C?style=for-the-badge&logo=apache-spark&logoColor=white)
![Databricks](https://img.shields.io/badge/Databricks-FF3621?style=for-the-badge&logo=databricks&logoColor=white)
![Status](https://img.shields.io/badge/Status-Active-00D26A?style=for-the-badge&logo=statuspage&logoColor=white)

</div>

---

## ğŸ“Œ VisÃ£o Geral

Esta Ã© uma **soluÃ§Ã£o robusta em PySpark** desenvolvida para a **distribuiÃ§Ã£o automatizada e balanceada** de clientes para gerentes de carteira em uma instituiÃ§Ã£o financeira. O sistema foi projetado para garantir uma alocaÃ§Ã£o eficiente, justa e rastreÃ¡vel, utilizando as melhores prÃ¡ticas de engenharia de dados.

### ğŸ¯ **Principais CaracterÃ­sticas**

<div align="center">

| CaracterÃ­stica | DescriÃ§Ã£o | Status |
|----------------|-----------|--------|
| âš¡ **AlocaÃ§Ã£o Inteligente por Chave Ãšnica** | Garante que clientes e gerentes sejam agrupados por uma chave de negÃ³cio comum (`chave_unica`) | âœ… |
| âš–ï¸ **Balanceamento RandÃ´mico** | Assegura uma distribuiÃ§Ã£o equitativa de clientes entre os gerentes qualificados, evitando sobrecarga | âœ… |  
| ğŸ” **ValidaÃ§Ã£o Rigorosa de Dados** | Implementa checagens para prevenir a duplicaÃ§Ã£o de clientes, garantindo que cada cliente seja atribuÃ­do a um Ãºnico gerente | âœ… |
| ğŸ“Š **Logging Detalhado** | Oferece rastreabilidade completa de todas as etapas do processo, desde a carga dos dados atÃ© a gravaÃ§Ã£o final | âœ… |

</div>

---

## ğŸ“Š Fluxo do Sistema

O pipeline de dados segue um fluxo claro e objetivo, executado em um ambiente Spark.

<div align="center">

```mermaid
graph TD
    A[ğŸ“‹ Base de Clientes] --> B{âš¡ Processamento Spark}
    C[ğŸ‘¥ Base de Gerentes] --> B
    B --> D[ğŸ”— Join por 'chave_unica']
    D --> E[ğŸ² DistribuiÃ§Ã£o RandÃ´mica Balanceada]
    E --> F[âœ… ValidaÃ§Ã£o de Qualidade e Duplicidade]
    F --> G[ğŸ’¾ Tabela Final]
    
    style A fill:#4CAF50,stroke:#388E3C,color:#fff
    style C fill:#2196F3,stroke:#0D47A1,color:#fff
    style B fill:#FF9800,stroke:#F57C00,color:#fff
    style G fill:#9C27B0,stroke:#6A1B9A,color:#fff
```

</div>

---

## ğŸ’¡ Como Funciona?

O processo Ã© orquestrado por meio de **funÃ§Ãµes modulares em PySpark**, garantindo clareza e manutenÃ§Ã£o.

### ğŸ”„ **1. Carga e PreparaÃ§Ã£o dos Dados**

Os dados de clientes e gerentes sÃ£o carregados a partir de tabelas Spark. Registros com a chave de junÃ§Ã£o nula sÃ£o descartados para garantir a qualidade da combinaÃ§Ã£o.

```python
# Carrega os dados de clientes e gerentes
clientes_df = spark.table("path.base_clientes")
gerentes_df = spark.table("path.base_gerentes")

# Filtra registros invÃ¡lidos
clientes_df = clientes_df.filter(F.col("chave_unica").isNotNull())
gerentes_df = gerentes_df.filter(F.col("chave_unica").isNotNull())
```

### âš¡ **2. Algoritmo de DistribuiÃ§Ã£o**

A distribuiÃ§Ã£o Ã© realizada combinando as tabelas de clientes e gerentes pela `chave_unica`. Para garantir que cada cliente seja atribuÃ­do a apenas um gerente de forma balanceada, utilizamos uma funÃ§Ã£o de janela (`Window`) particionada pelo nÃºmero do cliente (`nr_cli`) e ordenada de forma aleatÃ³ria (`F.rand()`).

```python
# Define a janela para distribuiÃ§Ã£o aleatÃ³ria
window_dist = Window.partitionBy("nr_cli").orderBy(F.rand())

# Realiza o join e aplica a regra de distribuiÃ§Ã£o
distribuicao = (clientes_df.join(gerentes_df, "chave_unica")
                .withColumn("row_number", F.row_number().over(window_dist))
                .filter(F.col("row_number") == 1)
                .drop("row_number"))
```

### ğŸ” **3. ValidaÃ§Ã£o da Integridade**

ApÃ³s a distribuiÃ§Ã£o, uma etapa de validaÃ§Ã£o crucial Ã© executada para confirmar que nÃ£o existem clientes atribuÃ­dos a mais de um gerente. O processo Ã© interrompido caso qualquer duplicidade seja encontrada.

```python
# Agrupa por cliente e conta as atribuiÃ§Ãµes
duplicados = df.groupBy("nr_cli").agg(F.count("*").alias("qtd")).filter(F.col("qtd") > 1)

# Verifica se foram encontradas duplicidades
if duplicados.count() > 0:
    raise Exception("Erro: Clientes atribuÃ­dos a mais de um gerente!")
```

---

## ğŸš€ Resultados e Performance

A soluÃ§Ã£o foi desenvolvida para entregar **resultados consistentes e performÃ¡ticos** em um ambiente distribuÃ­do.

<div align="center">

| **MÃ©trica** | **Resultado Esperado** |
|-------------|------------------------|
| ğŸ“Š **Clientes DistribuÃ­dos** | 100% dos clientes vÃ¡lidos, sem duplicidades |
| âš–ï¸ **Balanceamento** | DistribuiÃ§Ã£o justa e aleatÃ³ria, controlada por `F.rand()` |
| ğŸ“ˆ **Rastreabilidade** | Logs detalhados para cada etapa do processo |
| âš¡ **Performance** | Otimizado para processamento em larga escala com `spark.sql.shuffle.partitions` configurado para 600 partiÃ§Ãµes |

</div>

---

## ğŸ› ï¸ Como Executar

O script Ã© parametrizado por meio de uma classe de configuraÃ§Ã£o e pode ser executado em um ambiente Spark.

### âš™ï¸ **ConfiguraÃ§Ã£o do Ambiente**

<details>
<summary><b>ğŸ”§ ConfiguraÃ§Ã£o Inicial</b></summary>

A classe `ConfigDistribuicao` permite ajustar parÃ¢metros do processo.

```python
@dataclass
class ConfigDistribuicao:
    """ConfiguraÃ§Ãµes do processo de distribuiÃ§Ã£o"""
    limite_clientes: int = 1473
```

**ConfiguraÃ§Ãµes adicionais recomendadas:**
```python
# ConfiguraÃ§Ã£o do Spark para otimizaÃ§Ã£o
spark.conf.set("spark.sql.shuffle.partitions", "600")
spark.conf.set("spark.sql.adaptive.enabled", "true")
spark.conf.set("spark.sql.adaptive.coalescePartitions.enabled", "true")
```

</details>

### ğŸš€ **ExecuÃ§Ã£o do Pipeline**

<details>
<summary><b>ğŸ¯ ExecuÃ§Ã£o em Cluster</b></summary>

O ponto de entrada do script Ã© a funÃ§Ã£o `main()`, que orquestra todas as etapas. Para submeter em um cluster, utilize o `spark-submit`.

```bash
# ExecuÃ§Ã£o em cluster YARN
spark-submit --master yarn --deploy-mode cluster distribuidor-clientes.py

# ExecuÃ§Ã£o com configuraÃ§Ãµes customizadas
spark-submit \
  --master yarn \
  --deploy-mode cluster \
  --num-executors 10 \
  --executor-cores 4 \
  --executor-memory 8g \
  --driver-memory 4g \
  distribuidor-clientes.py
```

**ExecuÃ§Ã£o local para desenvolvimento:**
```bash
# Modo local
spark-submit --master local[*] distribuidor-clientes.py
```

</details>

### ğŸ“Š **Monitoramento e Logs**

<details>
<summary><b>ğŸ“ˆ Acompanhamento da ExecuÃ§Ã£o</b></summary>

O andamento da execuÃ§Ã£o pode ser acompanhado pelos logs gerados em tempo real.

```
2023-10-27 10:00:00 - INFO - Carregando dados de clientes e gerentes...
2023-10-27 10:01:00 - INFO - Iniciando processo de distribuiÃ§Ã£o...
2023-10-27 10:02:00 - INFO - ValidaÃ§Ã£o concluÃ­da: cada cliente foi atribuÃ­do a um Ãºnico gerente.
2023-10-27 10:03:00 - INFO - === Processo concluÃ­do com sucesso ===
```

**Monitoramento via Spark UI:**
- Acesse `http://driver-node:4040` para acompanhar jobs em tempo real
- Visualize mÃ©tricas de performance e utilizaÃ§Ã£o de recursos
- Monitore o progresso de cada stage do pipeline

</details>

---

## ğŸ”§ Stack TecnolÃ³gica

<div align="center">

| **Tecnologia** | **Finalidade** | **VersÃ£o** |
|----------------|----------------|------------|
| ğŸ **Python** | Linguagem principal para a lÃ³gica do script | 3.8+ |
| âš¡ **PySpark** | Framework de processamento distribuÃ­do para manipulaÃ§Ã£o dos dados em larga escala | 3.4+ |
| ğŸ§± **Databricks** | Ambiente de execuÃ§Ã£o otimizado para workloads Spark (sugerido) | Latest |
| ğŸ“ **Git / GitHub** | Controle de versÃ£o e gerenciamento do cÃ³digo-fonte | - |

</div>

---

<div align="center">

### ğŸ”’ **Nota de Privacidade**

> Este projeto foi desenvolvido seguindo as **melhores prÃ¡ticas de privacidade de dados**. Qualquer informaÃ§Ã£o sensÃ­vel utilizada no desenvolvimento foi devidamente **anonimizada**.

---
