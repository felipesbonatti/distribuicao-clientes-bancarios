{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from pyspark.sql import SparkSession, DataFrame, functions as F \nfrom pyspark.sql.window import Window \nfrom pyspark import StorageLevel \nfrom datetime import datetime \nimport logging \nfrom typing import Tuple \nfrom dataclasses import dataclass\n\n@dataclass\nclass ConfigDistribuicao:\n    \"\"\"Configurações do processo de distribuição\"\"\"\n    limite_clientes: int = 1473\n\ndef setup_logging() -> logging.Logger:\n    \"\"\"Configura o logger\"\"\"\n    logger = logging.getLogger(\"distribuicao\")\n    if not logger.handlers:\n        handler = logging.StreamHandler()\n        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n        handler.setFormatter(formatter)\n        logger.addHandler(handler)\n        logger.setLevel(logging.INFO)\n    return logger\n\ndef get_spark_session(config: ConfigDistribuicao) -> SparkSession:\n    \"\"\"Inicializa a SparkSession\"\"\"\n    return (SparkSession.builder\n        .appName(\"DistribuicaoClientes\")\n        .config(\"spark.sql.shuffle.partitions\", \"600\")\n        .getOrCreate())\n\ndef load_data(spark: SparkSession, logger: logging.Logger) -> Tuple[DataFrame, DataFrame]:\n    \"\"\"Carrega dados de clientes e gerentes\"\"\"\n    logger.info(\"Carregando dados de clientes e gerentes...\")\n   \n    # Carrega os dados\n    clientes_df = spark.table(\"path.base_clientes\")\n    gerentes_df = spark.table(\"path.base_gerentes\")\n\n    # Verificação inicial dos dados\n    logger.info(f\"Total de clientes carregados: {clientes_df.count()}\")\n\n    clientes_df.show(10, truncate=False)\n    gerentes_df.show(10, truncate=False)\n\n    logger.info(f\"Total de gerentes carregados: {gerentes_df.count()}\")\n\n    # Ajustar filtro para incluir apenas registros válidos\n    clientes_df = clientes_df.filter(F.col(\"chave_unica\").isNotNull())\n    gerentes_df = gerentes_df.filter(F.col(\"chave_unica\").isNotNull())\n\n    # Verificação após filtro\n    logger.info(f\"Total de clientes após filtro: {clientes_df.count()}\")\n    logger.info(f\"Total de gerentes após filtro: {gerentes_df.count()}\")\n\n    return clientes_df, gerentes_df\n\ndef distribuir_clientes(clientes_df: DataFrame, gerentes_df: DataFrame, config: ConfigDistribuicao, logger: logging.Logger) -> DataFrame:\n    \"\"\"Realiza a distribuição de clientes para gerentes\"\"\"\n    logger.info(\"Iniciando processo de distribuição...\")\n    \n    # Faz a combinação entre clientes e gerentes com a mesma chave `chave_unica`\n    combinacao = clientes_df.join(gerentes_df, \"chave_unica\")\n    \n    # Define uma janela para balancear a distribuição entre os gerentes dentro de cada `chave_unica`\n    window_dist = Window.partitionBy(\"nr_cli\").orderBy(F.rand())\n    \n    # Atribui um índice de linha para cada combinação de cliente e gerente\n    distribuicao = combinacao.withColumn(\n        \"row_number\",\n        F.row_number().over(window_dist)\n    ).filter(F.col(\"row_number\") == 1).drop(\"row_number\")\n\n    # Verifica se todos os clientes foram distribuídos\n    clientes_distribuidos = distribuicao.select(\"nr_cli\").distinct().count()\n    total_clientes = clientes_df.select(\"nr_cli\").distinct().count()\n\n    if clientes_distribuidos != total_clientes:\n        raise Exception(\"Erro: Nem todos os clientes foram distribuídos!\")\n\n    logger.info(f\"Distribuição concluída: {distribuicao.count()} clientes atribuídos.\")\n    return distribuicao\n\ndef validar_distribuicao(df: DataFrame, logger: logging.Logger) -> None:\n    \"\"\"Valida a distribuição realizada\"\"\"\n    logger.info(\"Validando a distribuição...\")\n    duplicados = df.groupBy(\"nr_cli\").agg(F.count(\"*\").alias(\"qtd\")).filter(F.col(\"qtd\") > 1)\n    duplicados_count = duplicados.count()\n \n    if duplicados_count > 0:\n        logger.error(f\"Encontrados {duplicados_count} CPFs duplicados na distribuição.\")\n        raise Exception(\"Erro: Clientes atribuídos a mais de um gerente!\")\n \n    logger.info(\"Validação concluída: cada cliente foi atribuído a um único gerente.\")\n\n\ndef salvar_resultado(df: DataFrame, logger: logging.Logger) -> None:\n    \"\"\"Salva os resultados da distribuição\"\"\"\n    logger.info(\"Salvando os resultados da distribuição...\")\n    \n    # Selecionar os campos desejados\n    tabela_final = df.select(\"CAMPO1\",\"CAMPO2\"...,\"CAMPO-N\")\n    \n    # Salvar os resultados\n    tabela_final.write.saveAsTable('path.prenome', mode='overwrite', overwriteSchema='true', mergeSchema='true')\n    logger.info(\"Resultados salvos com sucesso.\")\n\n\ndef main():\n    config = ConfigDistribuicao()\n    spark = get_spark_session(config)\n    logger = setup_logging()\n \n    logger.info(\"=== Início do processo de distribuição ===\")\n    try:\n        # Carregamento dos dados\n        clientes_df, gerentes_df = load_data(spark, logger)\n \n        # Distribuição de clientes\n        resultado_df = distribuir_clientes(clientes_df, gerentes_df, config, logger)\n \n        # Validação dos resultados\n        validar_distribuicao(resultado_df, logger)\n \n        # Salvamento dos resultados\n        salvar_resultado(resultado_df, logger)\n \n        logger.info(\"=== Processo concluído com sucesso ===\")\n \n    except Exception as e:\n        logger.error(f\"Erro crítico: {str(e)}\")\n        raise\n\nif __name__ == \"__main__\":\n    main()\n    \n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}